{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxtKGCzdbgbHOqqNjcBEUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52015/Gen_AI_2303A52015/blob/main/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9wL74ypt-eTs"
      },
      "outputs": [],
      "source": [
        "y=[10,20,30,40,50]\n",
        "yp=[10.2,20.5,30.3,40.8,50.6]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=(y[i]-yp[i])**2\n",
        "mean_square_error=sum/len(y)\n",
        "print('the mean square error of the above data is: ',mean_square_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d-74LIl-yiJ",
        "outputId": "8c9057f7-8736-43bf-ec04-d855abdbf1ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean square error of the above data is:  0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UadlKrXN_Anm",
        "outputId": "0732f4f6-a233-4eca-c4f9-961e5546a561"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kphCURFM_EEj",
        "outputId": "2538c790-151b-462a-ca70-fc23cbea148e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "sTo79G6S_Nnk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76uKNAc4_SNf",
        "outputId": "1014e9bb-59e4-44b6-ebb0-dd72498b8380"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZTEE92m_sS0",
        "outputId": "428550da-02d7-42f6-9c02-abd514cdf919"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSxWJBYO_4Sn",
        "outputId": "c9ef09ed-ec57-4f61-d152-bd64386efcbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "JxQeCJGz_7cM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLJvrf_vAHar",
        "outputId": "a7df3087-50ca-4995-9a05-04b0e64ab5ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y, yp)\n",
        "print('The Mean Absolute Error is:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "penwOMLvAbdg",
        "outputId": "b8e59245-afbf-45aa-ae75-f8e2bf21d712"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Absolute Error is: 0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = mse**0.5  # RMSE is the square root of MSE\n",
        "print('The Root Mean Squared Error is:', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb5N_-DtAhQP",
        "outputId": "ff0ccb92-786e-4dcd-ffd3-80f1866885af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Root Mean Squared Error is: 0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "yact=[0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2]\n",
        "ypred=[0,0,1,1,2,2,0,1,1,1,2,0,2,1,1,2]"
      ],
      "metadata": {
        "id": "mmOSdoidAqh2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(len(yact)):\n",
        "    l.append([yact[i],ypred[i]])\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOytHgjIA1U5",
        "outputId": "23b58d10-0e1b-42bd-da2d-1c329c3ed2a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [0, 1], [0, 1], [0, 2], [1, 2], [1, 0], [1, 1], [1, 1], [1, 1], [1, 2], [2, 0], [2, 2], [2, 1], [2, 1], [2, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yact_set=list(sorted(set(yact)))\n",
        "yact_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTQFoLe3A4LI",
        "outputId": "a77aa280-75ed-4ce7-b9c5-6b74c203cae6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=[]\n",
        "for i in yact_set:\n",
        "  temp=[]\n",
        "  for j in yact_set:\n",
        "    temp.append(l.count([i,j]))\n",
        "  cm.append(temp)"
      ],
      "metadata": {
        "id": "Xa93P805A9hD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"confusionmatrix of above data is:\\n\",np.array(cm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3fMlLB2BUlk",
        "outputId": "2909e4e9-1cd1-47d0-d033-980b9513e47d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusionmatrix of above data is:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_precision_recall_f1(cm):\n",
        "    total = builtins.sum(builtins.sum(row) for row in cm)\n",
        "    num_classes = len(cm)\n",
        "    precision = [0] * num_classes\n",
        "    recall = [0] * num_classes\n",
        "    f1_score = [0] * num_classes\n",
        "    tp_mat = []\n",
        "    fp_mat = []\n",
        "    fn_mat = []\n",
        "    tn_mat = []\n",
        "\n",
        "\n",
        "    for i in range(num_classes):  # Iterate over each class (rows)\n",
        "        # Calculate precision for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fp = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fp += cm[j][i]  # False Positives for class i\n",
        "        if tp + fp != 0:  # Avoid division by zero\n",
        "            precision[i] = tp / (tp + fp)\n",
        "\n",
        "        # Calculate recall for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fn = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fn += cm[i][j]  # False Negatives for class i\n",
        "        if tp + fn != 0:  # Avoid division by zero\n",
        "            recall[i] = tp / (tp + fn)\n",
        "                    # Calculate F1-score for class i\n",
        "        if precision[i] + recall[i] != 0:  # Avoid division by zero\n",
        "            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "\n",
        "        tp_mat.append(tp)\n",
        "        fp_mat.append(fp)\n",
        "        fn_mat.append(fn)\n",
        "        tn_mat.append(total - tp - fp - fn)  # Use the total calculated outside the loop\n",
        "\n",
        "    # Return total along with other metrics\n",
        "    return precision, recall, f1_score, tp_mat, fp_mat, fn_mat, tn_mat, total\n",
        "\n",
        "import builtins # Import builtins module\n",
        "# Assuming 'cm' is defined as in your previous code\n",
        "precision_values, recall_values, f1_values, tp_mat, fp_mat, fn_mat, tn_mat, total = calculate_precision_recall_f1(cm)\n",
        "\n",
        "# Print results for each class\n",
        "for i in range(len(precision_values)):\n",
        "    print(f\"Class {i} - Precision: {precision_values[i]}, Recall: {recall_values[i]}, F1-Score: {f1_values[i]}\")\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"\\nOverall Accuracy: {np.sum(tp_mat)/total}\") # Using the calculated 'total' here\n",
        "print(f\"Overall Precision: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fp_mat))}\")\n",
        "print(f\"Overall Recall: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fn_mat)):.4f}\")\n",
        "print(f\"Overall F1-Score: {np.mean(f1_values)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTJwYq3ZCfUQ",
        "outputId": "8298d139-5cd5-42c2-9564-ca7426e6bf25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 - Precision: 0.5, Recall: 0.4, F1-Score: 0.4444444444444445\n",
            "Class 1 - Precision: 0.42857142857142855, Recall: 0.5, F1-Score: 0.4615384615384615\n",
            "Class 2 - Precision: 0.4, Recall: 0.4, F1-Score: 0.4000000000000001\n",
            "\n",
            "Overall Accuracy: 0.4375\n",
            "Overall Precision: 0.4375\n",
            "Overall Recall: 0.4375\n",
            "Overall F1-Score: 0.43532763532763535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(yact, ypred))\n",
        "\n",
        "# Classification Report (Precision, Recall, F1)\n",
        "print(\"Classification Report:\\n\", classification_report(yact, ypred))\n",
        "\n",
        "# Individual Metrics\n",
        "accuracy = accuracy_score(yact, ypred)\n",
        "precision = precision_score(yact, ypred, average='weighted')\n",
        "recall = recall_score(yact, ypred, average='weighted')\n",
        "f1 = f1_score(yact, ypred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbJYXxGwCs8P",
        "outputId": "fb8d6ad5-73ec-42f2-a06d-20cc8c7f74d8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44         5\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.44      0.43      0.44        16\n",
            "weighted avg       0.44      0.44      0.44        16\n",
            "\n",
            "Accuracy: 0.4375\n",
            "Precision: 0.4419642857142857\n",
            "Recall: 0.4375\n",
            "F1-Score: 0.43696581196581197\n"
          ]
        }
      ]
    }
  ]
}