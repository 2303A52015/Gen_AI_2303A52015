{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "2303a52015_gen_ai_assignment_4.5ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52015/Gen_AI_2303A52015/blob/main/2303a52015_gen_ai_assignment_4_5ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        " layer). Assume a sigmoid activation function shown in the equation 1 in the output layer.\n",
        " f(x) = 1\n",
        " 1 +e−x\n",
        " (1)\n",
        " • Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        " update weights and bias parameters of the ANN model with training data shown in Table\n",
        " 3.\n",
        " ©Dr. Venkataramana Veeramsetty, Professor\n",
        " Pag. 1 de 2\n",
        "II- B.Tech (CS& AI)\n",
        " Tabela 3: Training Data\n",
        " Generative AI- Assignment- 4\n",
        " x1 x2 x3 y\n",
        " 0.1 0.2 0.3 0.5349\n",
        " 0.2 0.3 0.4 0.5498\n",
        " 0.3 0.4 0.5 0.5646\n",
        " 0.5 0.6 0.7 0.5939\n",
        " 0.1 0.3 0.5 0.5548\n",
        " 0.2 0.4 0.6 0.5695\n",
        " 0.3 0.5 0.7 0.5842\n",
        " 0.4 0.6 0.8 0.5987\n",
        " 0.5 0.7 0.1 0.5548\n",
        " Tabela 4: Test Data\n",
        " x1 x2 x3 y\n",
        " 0.6 0.7 0.8 0.6083\n",
        " 0.7 0.8 0.9 0.6225\n",
        " • Calculate the mean square error with training and testing data shown in Table 4.\n",
        " • Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        " output with deployed ANN model\n",
        " • Expected learning Outcomes from this assignment related to python– Students are able to understand how backpropagation algorithm helps to update model\n",
        " parameters of ANN– Students are able to write code in python for backpropagation algorithm– Students are able to design architecture of ANN based on problem statement– Students are able to derive mathematical expression for change in weights and bias\n",
        " parameters for different activation functions\n",
        " • Naming cinvention– Report File Name: RollNo_Week No._Assignment No.\n",
        " Date: 2025-01-23\n",
        " Dr. Venkataramana Veeramsetty, Prof"
      ],
      "metadata": {
        "id": "Q9rhqiIifkzK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlSDuvdzZqvH",
        "outputId": "1ff68c1e-3128-4055-e454-01a7e7968bd8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Weights: [0.12395376 0.18751978 0.30162965]\n",
            "Final Bias: -0.0023614390832260575\n",
            "Train MSE: 1.7908073772341483e-07\n",
            "Test MSE: 1.451392901894969e-06\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Mean Squared Error function\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Training Data (Table 3)\n",
        "X_train = np.array([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.2, 0.3, 0.4],\n",
        "    [0.3, 0.4, 0.5],\n",
        "    [0.5, 0.6, 0.7],\n",
        "    [0.1, 0.3, 0.5],\n",
        "    [0.2, 0.4, 0.6],\n",
        "    [0.3, 0.5, 0.7],\n",
        "    [0.4, 0.6, 0.8],\n",
        "    [0.5, 0.7, 0.1]\n",
        "])\n",
        "y_train = np.array([0.5349, 0.5498, 0.5646, 0.5939, 0.5548, 0.5695, 0.5842, 0.5987, 0.5548])\n",
        "\n",
        "# Initialize weights and bias\n",
        "np.random.seed(0)\n",
        "weights = np.random.rand(3)\n",
        "bias = np.random.rand()\n",
        "learning_rate = 0.1\n",
        "epochs = 1000\n",
        "\n",
        "# Training loop according to flowchart\n",
        "for epoch in range(epochs):\n",
        "    for i in range(len(X_train)):\n",
        "        x_sample = X_train[i]\n",
        "        y_true = y_train[i]\n",
        "\n",
        "        # Forward propagation\n",
        "        z = np.dot(x_sample, weights) + bias\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        # Compute gradients\n",
        "        error = y_true - y_pred\n",
        "        grad_weights = -2 * error * sigmoid_derivative(y_pred) * x_sample\n",
        "        grad_bias = -2 * error * sigmoid_derivative(y_pred)\n",
        "\n",
        "        # Update weights and bias\n",
        "        weights -= learning_rate * grad_weights\n",
        "        bias -= learning_rate * grad_bias\n",
        "\n",
        "# Testing Data (Table 4)\n",
        "X_test = np.array([\n",
        "    [0.6, 0.7, 0.8],\n",
        "    [0.7, 0.8, 0.9]\n",
        "])\n",
        "y_test = np.array([0.6083, 0.6225])\n",
        "\n",
        "# Predictions on test data\n",
        "y_test_pred = sigmoid(np.dot(X_test, weights) + bias)\n",
        "\n",
        "# Calculate Mean Squared Error for training and testing\n",
        "mse_train = mse(y_train, sigmoid(np.dot(X_train, weights) + bias))\n",
        "mse_test = mse(y_test, y_test_pred)\n",
        "\n",
        "print(\"Final Weights:\", weights)\n",
        "print(\"Final Bias:\", bias)\n",
        "print(\"Train MSE:\", mse_train)\n",
        "print(\"Test MSE:\", mse_test)\n",
        "\n",
        "# User input prediction\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "user_pred = sigmoid(np.dot([x1, x2, x3], weights) + bias)\n",
        "print(\"Predicted Output:\", user_pred)\n"
      ]
    }
  ]
}